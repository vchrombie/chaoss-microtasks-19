{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Microtask-1\n",
    "\n",
    "> Produce a notebook showing (and producing) a list with the activity per quarter: number of new committers, submitters of issues, and submitters of pull/merge requests, number of items (commits, issues, pull/merge requests), number of repositories with new items (all of this per quarter) as a table and as a CSV file using plain python3 (no pandas).\n",
    "\n",
    "\n",
    "I am using the same data source file which is used in the [microtask-0](https://github.com/vchrombie/chaoss-microtasks/blob/master/microtask-0/microtask-0.ipynb) i.e, [elasticsearch-py](https://github.com/elastic/elasticsearch-py) project which is located in the `data/` folder of the repository."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing the neccessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# json library is used to handle json files, here, it is the data source retrieved by the perceval module.\n",
    "import json \n",
    "# to write and read csv files, to show the output in the end\n",
    "import csv  \n",
    "\n",
    "# to handle the time formats, like to determine 'created_at' of an issue or pr.\n",
    "import datetime  \n",
    "# dictionaries are a convenient way to store data for later retrieval by name (key).\n",
    "from collections import defaultdict  \n",
    "\n",
    "# it is used to send http requests, I used to get the year in which the project created to do the analysis, using requests and github api.\n",
    "import requests \n",
    "# open source python module to pretty print a csv file. ref: https://github.com/jazzband/prettytable\n",
    "from prettytable import from_csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "repos = ('data','data2')\n",
    "\n",
    "\n",
    "# there are three types of contributions - commit, issue, and pr\n",
    "# so, I created a tuple which has the contribution types\n",
    "ctypes = ('commit','pull_request','issue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Functions to return the details of the contribution types\n",
    "\n",
    "_Commit_ has a different json structure when compared to *issue* and *pull_request*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get the required details of commits\n",
    "# commit has a different json structure unlike issue/pr\n",
    "\n",
    "def details_commit(commit):\n",
    "    # load the commit data into the object\n",
    "    data = commit['data']\n",
    "    # traverse through the json line to find the required data\n",
    "    content ={\n",
    "            # get the hash of the commit\n",
    "            'hash': data['commit'],\n",
    "            # get the author_name\n",
    "            'author': data['Author'],  \n",
    "            # get the date at which the commit was created\n",
    "            'created_date': datetime.datetime.strptime(data['CommitDate'],\"%a %b %d %H:%M:%S %Y %z\")  \n",
    "    }\n",
    "    return content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to get the required details of issue/pull requests\n",
    "# as issue/pr has the same json structure in the data source scraped by perceval\n",
    "# I wrote a single function to get the either issue/pr details \n",
    "\n",
    "def details_ipr(item):\n",
    "    # load the commit data into the object\n",
    "    data = item['data']\n",
    "    # traverse through the json line to find the required data\n",
    "    content ={\n",
    "            # get the hash of the issue/pr\n",
    "            'hash': data['id'],\n",
    "            # get the author_name\n",
    "            'author': data['user']['login'],  \n",
    "            # get the date at which the issue/pr was created\n",
    "            'created_date': datetime.datetime.strptime(data['created_at'],\"%Y-%m-%dT%H:%M:%SZ\")  \n",
    "    }\n",
    "    return content "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dividing the data source into contribution types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# contents is to store the details of each contribution whether it is a commit, issue or pr.\n",
    "# using a defaultdict of list so that I can store the sorted details according to the ctype as (key, value) \n",
    "repocontent = defaultdict(list)\n",
    "contents = defaultdict(list)\n",
    "\n",
    "# to filter out commit, issue, pr details from the data source and store them seperately in dict.\n",
    "# loading the file into an object\n",
    "\n",
    "for repo in repos:\n",
    "    with open('../data/%s.json'%repo) as datasrc:\n",
    "        for line in datasrc:\n",
    "            # load the line in the json format so as to iterate to get the required results\n",
    "            line = json.loads(line)\n",
    "            # if it is a commit, get the details of commit\n",
    "            if line['category'] == 'commit':    \n",
    "                content = details_commit(line) \n",
    "            # if it is a issue, get the details of issue\n",
    "            elif line['category'] == 'issue':    \n",
    "                content = details_ipr(line)\n",
    "            # if it is a pr, get the details of pr\n",
    "            elif line['category'] == 'pull_request':    \n",
    "                content = details_ipr(line) \n",
    "            # add the (key, value) to the list\n",
    "            contents[line['category']].append(content)\n",
    "        repocontent[repo].append(contents)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "repodata = defaultdict(dict)\n",
    "\n",
    "for repo in repos:\n",
    "    for ctype in ctypes:\n",
    "        for item in contents[ctype]:\n",
    "            \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# initializing a empty quaters list to store the quaters of the project\n",
    "quarters = []\n",
    "\n",
    "# using again a defaultdict(list) to store the activites and it's vaues as quaters.\n",
    "activities = defaultdict(list)\n",
    "\n",
    "# newcontributors as list in order to append each time a new contributor arrives\n",
    "newcontributors = defaultdict(list)\n",
    "# oldcontributors as set so that dupplicated can't crawl into the set\n",
    "oldcontributors = defaultdict(set)\n",
    "\n",
    "# generating the quaters from `created`  year to `present`  year which are scraped earlier\n",
    "for year,quarter,start,end in quarterwise(created,present):\n",
    "    # add `Qi yyyy`  format as a quater in the quaters list\n",
    "    quarters.append(r\"Q%d %d\"%(quarter+1,year))\n",
    "    # iterating through the contribution types in order to segregate their values into the dict\n",
    "    for ctype in ctypes:\n",
    "        # initailizing the counts to zero\n",
    "        activity =  newcontributor =  0 \n",
    "        # using the earlier contents dict to check in which quater the data falls\n",
    "        for item in contents[ctype]:\n",
    "            # checking if the date of contribtion (commit/issue/pr) created is in between start & end\n",
    "            if start<=item['created_date'].replace(tzinfo=None)<=end:\n",
    "                # it is counted as an activity in that quater\n",
    "                activity+=1\n",
    "                # checking the author if he is a previous contributor already\n",
    "                if item['author'] not in oldcontributors[ctype]:\n",
    "                    # if not, he is counted as a new contributor\n",
    "                    newcontributor+=1\n",
    "                    # and added him to the oldcontributors set\n",
    "                    oldcontributors[ctype].add(item['author'])\n",
    "        # total activities are counted and added to the dict as (ctype, value) in list\n",
    "        activities[ctype].append(activity)\n",
    "        # newcontributors, either through commit/issue/pr are added to the dict as (ctype, value) in list\n",
    "        newcontributors[ctype].append(newcontributor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Showing the Activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to print the total activity \n",
    "print(\"Quaterwise Total Activity\\n\")\n",
    "for item in dict(activities):\n",
    "    # print the total activity quaterly\n",
    "    print (item, dict(activities)[item])  \n",
    "\n",
    "# small hack to produce a new line to make space. \n",
    "#just for the funcs to look symmetric while printing :P\n",
    "print() \n",
    "\n",
    "# to print the new activity \n",
    "print(\"Quaterwise New Contributors Activity\\n\")\n",
    "# iterating through the newcontributors dict \n",
    "for item in dict(newcontributors):\n",
    "    # print the new activity quaterly\n",
    "    print (item, dict(activities)[item])  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create a CSV to store the Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add headers to the csv file \n",
    "header = ['Quarter','# Commits','# PullRequests','# Issues','# NewCommitters','# NewIssueSubmitters','# NewPRSubmitters' ]\n",
    "# opening a new csv to write the data into it.\n",
    "with open('elasticsearch-py.csv', 'w') as file:\n",
    "    # intilize the writer object\n",
    "    writer = csv.writer(file)\n",
    "    # wring the header first\n",
    "    writer.writerow(header)\n",
    "    # to map the similar index of multiple containers so that they can be added in single entity i.e, rows\n",
    "    rows = zip(quarters,activities['commit'],activities['pull_request'],activities['issue'],newcontributors['commit'],newcontributors['pull_request'],newcontributors['issue'])\n",
    "    # writing all the rows at a time\n",
    "    writer.writerows(rows)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Show the Output as a table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to show the output in the form of a table\n",
    "# load the csv file into a object\n",
    "with open(\"elasticsearch-py.csv\", \"r\") as csvfile: \n",
    "    # using from_csv method from prettytable module\n",
    "    csvtable = from_csv(csvfile)\n",
    "    \n",
    "# print the prettified table\n",
    "print(csvtable)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
