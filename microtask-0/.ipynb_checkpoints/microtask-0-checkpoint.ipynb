{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Microtask-0\n",
    "\n",
    "> Produce one notebook per data source (git, GitHub/GitLab issues, GitHub pull requests / GitLab merge requests) showing a summary of the contents of that file (number of items in it, and number of different identities in it counting authors/committers for git, submitters for issues and pull/merge requests). This microtask is mandatory, to show that you can retrieve data and produde a notebook showing it. In each notebook, include also the list of repositories retrieved, and the date of retrieval, using data available in the JSON file.\n",
    "\n",
    "This notebook gives you the analysis of [elasticsearch-py](https://github.com/elastic/elasticsearch-py) project. The source file is present in the `data/` folder of this repository.\n",
    "\n",
    "Date of Retrieval: 03/03/2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retreiving the data\n",
    "\n",
    "For retreiving the commit data\n",
    "\n",
    "```bash\n",
    "$ perceval git --json-line https://github.com/elastic/elasticsearch-py >> elasticsearch-py.json\n",
    "[2019-03-04 03:39:27,394] - Sir Perceval is on his quest.\n",
    "[2019-03-04 03:43:54,748] - Fetching commits: 'https://github.com/elastic/elasticsearch-py' git repository from 1970-01-01 00:00:00+00:00 to 2100-01-01 00:00:00+00:00; all branches\n",
    "[2019-03-04 03:44:15,614] - Fetch process completed: 1135 commits fetched\n",
    "[2019-03-04 03:44:15,614] - Sir Perceval completed his quest.\n",
    "```\n",
    "For retreiving the issues data\n",
    "\n",
    "```bash\n",
    "$ perceval github elastic elasticsearch-py --sleep-for-rate -t xxxx --category issue >> elasticsearch-py.json\n",
    "[2019-03-04 04:19:03,813] - Sir Perceval is on his quest.\n",
    "[2019-03-04 04:19:07,895] - Getting info for https://api.github.com/users/nkvoll\n",
    "...\n",
    "...\n",
    "[2019-03-04 04:43:23,674] - Sir Perceval completed his quest.\n",
    "```\n",
    "For retreiving the pull_requests data\n",
    "\n",
    "```bash\n",
    "$ perceval github elastic elasticsearch-py --sleep-for-rate -t xxxx --category pull_request >> elasticsearch-py.json\n",
    "[2019-03-04 05:19:03,813] - Sir Perceval is on his quest.\n",
    "[2019-03-04 05:19:07,895] - Getting info for https://api.github.com/users/nkvoll\n",
    "...\n",
    "...\n",
    "[2019-03-04 05:43:23,674] - Sir Perceval completed his quest.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can run the [sh.sh](https://github.com/vchrombie/chaoss-microtasks/blob/master/sh.sh) file to automate the retrieval of the date. All you need to do is to \n",
    "provide the GITHUB_TOKEN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# json library is used to handle json files, here, it is the data source retrieved by the perceval module.\n",
    "import json\n",
    "# to handle the time formats, like to determine 'created_at' of an issue or pr.\n",
    "import dateutil\n",
    "from datetime import datetime\n",
    "# dictionaries are a convenient way to store data for later retrieval by name (key).\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TimeStamp: 2019-03-05 20:33:11\n",
      "Project Retrieved: https://github.com/elastic/elasticsearch-py\n"
     ]
    }
   ],
   "source": [
    "# loading the file contents in an object\n",
    "with open('../data/elasticsearch-py.json') as file:\n",
    "    # load the line in the json format so as to iterate to get the required results\n",
    "    line= json.loads(file.readline())\n",
    "    \n",
    "# extract the date of retrieval from the data source\n",
    "# the data source stores the time when the line was actually scraped by the perceval\n",
    "print('TimeStamp:',datetime.utcfromtimestamp(int(line['timestamp'])).strftime('%Y-%m-%d %H:%M:%S'))\n",
    "print('Project Retrieved:',line['origin'])\n",
    "\n",
    "# reference: https://stackoverflow.com/questions/3682748/converting-unix-timestamp-string-to-readable-date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class Code_Changes\n",
    "\n",
    "This implementation uses data retrieved as described above.\n",
    "The implementation is encapsulated in the `Code_Changes` class,\n",
    "which gets all commits for a set of repositories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# T_DO: add summary code for issue and pull_requests - DONE in Microtask-6\n",
    "\n",
    "\n",
    "class Code_Changes:\n",
    "    \"\"\"\n",
    "    Class for Code_Changes for Git repositories.\n",
    "    \n",
    "    Objects are instantiated by specifying a file with the\n",
    "    commits obtained by Perceval from a set of repositories.\n",
    "        \n",
    "    :param path: Path to file with one Perceval JSON document per line\n",
    "    \"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    # function to summarize the commits\n",
    "    # it goes through th json lines and extracts the useful information from it\n",
    "    def _summarize_commit(commit):\n",
    "        \"\"\"\n",
    "        Compute a summary of a commit, suitable as a row in a dataframe\n",
    "        \"\"\"\n",
    "        #it gets the details from the json structure\n",
    "        \n",
    "        # origin gives the name of the repo\n",
    "        repo = commit['origin']\n",
    "        # loading the entire commit data into cdata so as to parse further\n",
    "        cdata = commit['data']\n",
    "        # creating an dict to store all the summary of the files\n",
    "        summary ={\n",
    "                # repository name\n",
    "                'repo': repo,\n",
    "                # hash id of the commit \n",
    "                'hash': cdata['commit'],\n",
    "                # author of the commit\n",
    "                'author': cdata['Author'],\n",
    "                # when did he sent the commit - date\n",
    "                'author_date': datetime.strptime(cdata['AuthorDate'],\"%a %b %d %H:%M:%S %Y %z\"),\n",
    "                # commit message\n",
    "                'commit': cdata['Commit'],\n",
    "                # commit date\n",
    "                'commit_date': datetime.strptime(cdata['CommitDate'],\"%a %b %d %H:%M:%S %Y %z\"),\n",
    "                # number of files changed\n",
    "                'files_no': len(cdata['files'])\n",
    "        }\n",
    "        #\n",
    "        actions = 0\n",
    "        for file in cdata['files']:\n",
    "            if 'action' in file:\n",
    "                actions += 1\n",
    "        summary['files_action'] = actions\n",
    "        summary['merge'] = 'Merge' in cdata\n",
    "        return summary\n",
    "\n",
    "    # starting funtion of the class \n",
    "    # this function prepares the file to be parsed\n",
    "    # divides the data source into three categories - commit, issue and pr\n",
    "    def __init__(self, path):\n",
    "        \"\"\"\n",
    "        Initilizes self.df, the dataframe with one row per commit.\n",
    "        \"\"\"\n",
    "        # loading the file contents as an object\n",
    "        with open(path) as datafile:\n",
    "            # content file - to store the contents of the commit\n",
    "            content =  defaultdict(list)\n",
    "            # initializing the commit count\n",
    "            commit_count = 0\n",
    "            # initializing the issue count\n",
    "            issue_count = 0\n",
    "            # initializing the pr count\n",
    "            pr_count = 0\n",
    "            for line in datafile:\n",
    "                line = json.loads(line)\n",
    "                # if the line is a commit >> summarize it\n",
    "                if line['category']=='commit':\n",
    "                    # increase the count of the commits\n",
    "                    commit_count+=1\n",
    "                    # sending for summarizing\n",
    "                    summary = self._summarize_commit(line)\n",
    "                    # add the summart to the contents\n",
    "                    for field in summary:\n",
    "                        content[field].append(summary[field])\n",
    "                # if the line is a issue >> increase the issue counter\n",
    "                elif line['category']=='issue':\n",
    "                    issue_count+=1\n",
    "                # if the line is a pr >> increase the pr counter\n",
    "                elif line['category']=='pull_request':\n",
    "                    pr_count+=1\n",
    "        # saving the instance of the content\n",
    "        self.content = content\n",
    "        # saving the instance of the commit count\n",
    "        self.commit_count = commit_count\n",
    "        # saving the instance of the issue count\n",
    "        self.issue_count = issue_count\n",
    "        # saving the instance of the pr count\n",
    "        self.pr_count = pr_count\n",
    "        \n",
    "    # method to return the total number of commits \n",
    "    def total_count(self):\n",
    "        \"\"\"\n",
    "        Total number of commits\n",
    "        \"\"\"\n",
    "        # as we computed the commit count already in __init__ and saved the instance\n",
    "        # we can directly return it\n",
    "        return self.commit_count\n",
    "    \n",
    "    \n",
    "    # method to calculate the count \n",
    "    def count(self, since = None, until = None, empty=True, merge=True, date='author_date'):\n",
    "        \"\"\"\n",
    "        Count number of commits\n",
    "        \n",
    "        :param since: Period start\n",
    "        :param until: Period end\n",
    "        :param empty: Include empty commits\n",
    "        :param merge: Include merge commits\n",
    "        :param  date: Kind of date ('author_date' or 'commit_date')\n",
    "        \"\"\"\n",
    "        # storing the contents in a temporary variable\n",
    "        c = self.content\n",
    "        # initializing the count\n",
    "        count = 0\n",
    "        # defining a set so as to avoid duplicates\n",
    "        unique = set()\n",
    "        # iterating through the files \n",
    "        for hash,date, files_action, merge_value in zip(c['hash'],c[date],c['files_action'],c['merge']):\n",
    "            current_count = 1\n",
    "            # ignoring the date\n",
    "            date= date.replace(tzinfo = None)  \n",
    "            if since and date < dateutil.parser.parse(since):\n",
    "                current_count = 0\n",
    "            if until and date > dateutil.parser.parse(until):\n",
    "                current_count = 0\n",
    "            if not empty and files_action == 0 :\n",
    "                current_count = 0\n",
    "            if not merge and merge_value:\n",
    "                current_count = 0\n",
    "            if hash not in unique:\n",
    "                count+=current_count\n",
    "                unique.add(hash)\n",
    "        return count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method `total_count()` implements `Total Count` aggregation for `Code_Changes`.\n",
    "\n",
    "Method `count()` implements `Count` aggregation for `Code_Changes`.\n",
    "It accepts parameters specified for the general metric:\n",
    "    \n",
    "* Period of time: `since` and `until`\n",
    "* Specific case if Git: `merge` and `empty`\n",
    "* `date`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples of use of the implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code changes total count: 1135\n",
      "Code changes count all period: 1135\n",
      "Code changes count from 2017-01-01 to 2019-07-01: 262\n",
      "Code changes count from 2017-01-01 to 2019-07-01 (no merge commits): 234\n",
      "Code changes count from 2017-01-01 to 2019-07-01 (no empty commits): 237\n"
     ]
    }
   ],
   "source": [
    "# giving the data source as an argument, calling the class file \n",
    "changes = Code_Changes('../data/elasticsearch-py.json')\n",
    "\n",
    "# printing all the results that can be extracted from the  source\n",
    "\n",
    "# printing count of total changes \n",
    "print(\"Code changes total count:\", changes.total_count())\n",
    "# printing changes count all period\n",
    "print(\"Code changes count all period:\", changes.count())\n",
    "# printing changes count from 2017-01-01 to 2019-07-01\n",
    "print(\"Code changes count from 2017-01-01 to 2019-07-01:\",changes.count(since=\"2017-01-01\", until=\"2019-07-01\"))\n",
    "# printing changes count with no merge commits\n",
    "print(\"Code changes count from 2017-01-01 to 2019-07-01 (no merge commits):\",changes.count(since=\"2017-01-01\", until=\"2019-07-01\", merge=False))\n",
    "# printing changes count with no empty commits\n",
    "print(\"Code changes count from 2017-01-01 to 2019-07-01 (no empty commits):\",changes.count(since=\"2017-01-01\", until=\"2019-07-01\", empty=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples showing peculiarities of git commits\n",
    "\n",
    "Let's prepare a dictionary, `commits`, with all commits retrieved,\n",
    "by reading the `elasticsearch-py.json` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# storing the contents in a temporary variable\n",
    "commits = changes.content\n",
    "# calling the commits_count funtion to return the total number of commits\n",
    "count = changes.commit_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive count of commits\n",
    "\n",
    "Let's compute number of commits the easiest way: just count all commits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code Commits (naive): 1135\n"
     ]
    }
   ],
   "source": [
    "# total number of commits\n",
    "print(\"Code Commits (naive):\", count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issues and PRs \n",
    "\n",
    "The `category` in the json file determines whether it is an issue or pull_request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary:\n",
      " Total Commits 1135 \n",
      " Total Issues 906 \n",
      " Total Pull Requests: 290\n"
     ]
    }
   ],
   "source": [
    "# printing the summary of the whole file\n",
    "print(\"Summary:\\n\", \"Total Commits\", changes.commit_count, \"\\n\", \"Total Issues\", changes.issue_count, \"\\n\", \"Total Pull Requests:\", changes.pr_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Total Summary  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Overall Summary-----\n",
      "\n",
      "Code changes total count: 1135\n",
      "Code changes count all period: 1135\n",
      "Code changes count from 2017-01-01 to 2019-07-01: 262\n",
      "Code changes count from 2017-01-01 to 2019-07-01 (no merge commits): 234\n",
      "Code changes count from 2017-01-01 to 2019-07-01 (no empty commits): 237\n",
      "Code Commits (naive): 1135\n",
      "Summary:\n",
      " Total Commits 1135 \n",
      " Total Issues 906 \n",
      " Total Pull Requests: 290\n"
     ]
    }
   ],
   "source": [
    "print('-----Overall Summary-----'+'\\n')\n",
    "\n",
    "print(\"Code changes total count:\", changes.total_count())\n",
    "print(\"Code changes count all period:\", changes.count())\n",
    "print(\"Code changes count from 2017-01-01 to 2019-07-01:\",changes.count(since=\"2017-01-01\", until=\"2019-07-01\"))\n",
    "print(\"Code changes count from 2017-01-01 to 2019-07-01 (no merge commits):\",changes.count(since=\"2017-01-01\", until=\"2019-07-01\", merge=False))\n",
    "print(\"Code changes count from 2017-01-01 to 2019-07-01 (no empty commits):\",changes.count(since=\"2017-01-01\", until=\"2019-07-01\", empty=False))\n",
    "print(\"Code Commits (naive):\", count)\n",
    "print(\"Summary:\\n\", \"Total Commits\", changes.commit_count, \"\\n\", \"Total Issues\", changes.issue_count, \"\\n\", \"Total Pull Requests:\", changes.pr_count)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
