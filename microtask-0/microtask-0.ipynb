{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Microtask-0\n",
    "\n",
    "> Produce one notebook per data source (git, GitHub/GitLab issues, GitHub pull requests / GitLab merge requests) showing a summary of the contents of that file (number of items in it, and number of different identities in it counting authors/committers for git, submitters for issues and pull/merge requests). This microtask is mandatory, to show that you can retrieve data and produde a notebook showing it. In each notebook, include also the list of repositories retrieved, and the date of retrieval, using data available in the JSON file.\n",
    "\n",
    "This notebook gives you the analysis of [elasticsearch-py](https://github.com/elastic/elasticsearch-py) project. The source file is present in the `data/` folder of this repository.\n",
    "\n",
    "Date of Retrieval: 03/03/2019"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install perceval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Retreiving the data\n",
    "\n",
    "For retreiving the commit data\n",
    "\n",
    "```bash\n",
    "$ perceval git --json-line https://github.com/elastic/elasticsearch-py >> elasticsearch-py.json\n",
    "[2019-03-04 03:39:27,394] - Sir Perceval is on his quest.\n",
    "[2019-03-04 03:43:54,748] - Fetching commits: 'https://github.com/elastic/elasticsearch-py' git repository from 1970-01-01 00:00:00+00:00 to 2100-01-01 00:00:00+00:00; all branches\n",
    "[2019-03-04 03:44:15,614] - Fetch process completed: 1135 commits fetched\n",
    "[2019-03-04 03:44:15,614] - Sir Perceval completed his quest.\n",
    "```\n",
    "For retreiving the issues data\n",
    "\n",
    "```bash\n",
    "$ perceval github elastic elasticsearch-py --sleep-for-rate -t xxxx --category issue >> elasticsearch-py.json\n",
    "[2019-03-04 04:19:03,813] - Sir Perceval is on his quest.\n",
    "[2019-03-04 04:19:07,895] - Getting info for https://api.github.com/users/nkvoll\n",
    "...\n",
    "...\n",
    "[2019-03-04 04:43:23,674] - Sir Perceval completed his quest.\n",
    "```\n",
    "For retreiving the pull_requests data\n",
    "\n",
    "```bash\n",
    "$ perceval github elastic elasticsearch-py --sleep-for-rate -t xxxx --category pull_request >> elasticsearch-py.json\n",
    "[2019-03-04 05:19:03,813] - Sir Perceval is on his quest.\n",
    "[2019-03-04 05:19:07,895] - Getting info for https://api.github.com/users/nkvoll\n",
    "...\n",
    "...\n",
    "[2019-03-04 05:43:23,674] - Sir Perceval completed his quest.\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can run the [sh.sh](https://github.com/vchrombie/chaoss-microtasks/blob/master/sh.sh) file to automate the retrieval of the date. All you need to do is to \n",
    "provide the GITHUB_TOKEN."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Also, you can download the data source files from the notebook itself. Just provide your `github_token` and run the below cell.\n",
    "\n",
    "Since it takes a long time to download a source of a large repository, I have downloaded the source files and I am using it directlyw which will be availabel in `data/` folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# please provide your github personal token here\n",
    "#github_token = \"\"\n",
    "\n",
    "#!perceval git --json-line https://github.com/elastic/elasticsearch-py >> ../data/elasticsearch-py.json\n",
    "#!perceval github elastic elasticsearch-py --sleep-for-rate -t $github_token --category issue >> ../data/elasticsearch-py.json\n",
    "#!perceval github elastic elasticsearch-py --sleep-for-rate -t $github_token --category pull_request >> ../data/elasticsearch-py.json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the necessary modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import dateutil\n",
    "\n",
    "from datetime import datetime\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TimeStamp: 2019-03-05 20:33:11\n",
      "Project Retrieved: https://github.com/elastic/elasticsearch-py\n"
     ]
    }
   ],
   "source": [
    "with open('../data/elasticsearch-py.json') as file:\n",
    "    line= json.loads(file.readline())\n",
    "    \n",
    "# extract the date of retrieval from the data source\n",
    "print('TimeStamp:',datetime.utcfromtimestamp(int(line['timestamp'])).strftime('%Y-%m-%d %H:%M:%S'))\n",
    "print('Project Retrieved:',line['origin'])\n",
    "\n",
    "# reference: https://stackoverflow.com/questions/3682748/converting-unix-timestamp-string-to-readable-date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Class Code_Changes\n",
    "\n",
    "This implementation uses data retrieved as described above.\n",
    "The implementation is encapsulated in the `Code_Changes` class,\n",
    "which gets all commits for a set of repositories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Code_Changes:\n",
    "    \"\"\"\n",
    "    Class for Code_Changes for Git repositories.\n",
    "    \n",
    "    Objects are instantiated by specifying a file with the\n",
    "    commits obtained by Perceval from a set of repositories.\n",
    "        \n",
    "    :param path: Path to file with one Perceval JSON document per line\n",
    "    \"\"\"\n",
    "    \n",
    "    @staticmethod\n",
    "    def _summarize_commit(commit):\n",
    "        \"\"\"\n",
    "        Compute a summary of a commit, suitable as a row in a dataframe\n",
    "        \"\"\"\n",
    "        repo = commit['origin']\n",
    "        cdata = commit['data']\n",
    "        summary ={\n",
    "                'repo': repo,\n",
    "                'hash': cdata['commit'],\n",
    "                'author': cdata['Author'],\n",
    "                'author_date': datetime.strptime(cdata['AuthorDate'],\"%a %b %d %H:%M:%S %Y %z\"),\n",
    "                'commit': cdata['Commit'],\n",
    "                'commit_date': datetime.strptime(cdata['CommitDate'],\"%a %b %d %H:%M:%S %Y %z\"),\n",
    "                'files_no': len(cdata['files'])\n",
    "        }\n",
    "        actions = 0\n",
    "        for file in cdata['files']:\n",
    "            if 'action' in file:\n",
    "                actions += 1\n",
    "        summary['files_action'] = actions\n",
    "        summary['merge'] = 'Merge' in cdata\n",
    "        return summary\n",
    "\n",
    "    # divides the data source into three categories - commit, issue and pr\n",
    "    def __init__(self, path):\n",
    "        \"\"\"\n",
    "        Initilizes self.df, the dataframe with one row per commit.\n",
    "        \"\"\"\n",
    "        with open(path) as datafile:\n",
    "            content =  defaultdict(list)\n",
    "            commit_count = 0\n",
    "            issue_count = 0\n",
    "            pr_count = 0\n",
    "            for line in datafile:\n",
    "                line = json.loads(line)\n",
    "                if line['category']=='commit':\n",
    "                    commit_count+=1\n",
    "                    summary = self._summarize_commit(line)\n",
    "                    for field in summary:\n",
    "                        content[field].append(summary[field])\n",
    "                elif line['category']=='issue':\n",
    "                    issue_count+=1\n",
    "                elif line['category']=='pull_request':\n",
    "                    pr_count+=1\n",
    "        self.content = content\n",
    "        self.commit_count = commit_count\n",
    "        self.issue_count = issue_count\n",
    "        self.pr_count = pr_count\n",
    "        \n",
    "    # method to return the total number of commits \n",
    "    def total_count(self):\n",
    "        \"\"\"\n",
    "        Total number of commits\n",
    "        \"\"\"\n",
    "        # as we computed the commit count already in __init__ and saved the instance\n",
    "        # we can directly return it\n",
    "        return self.commit_count\n",
    "    \n",
    "    \n",
    "    def count(self, since = None, until = None, empty=True, merge=True, date='author_date'):\n",
    "        \"\"\"\n",
    "        Count number of commits\n",
    "        \n",
    "        :param since: Period start\n",
    "        :param until: Period end\n",
    "        :param empty: Include empty commits\n",
    "        :param merge: Include merge commits\n",
    "        :param  date: Kind of date ('author_date' or 'commit_date')\n",
    "        \"\"\"\n",
    "        c = self.content\n",
    "        count = 0\n",
    "        unique = set()\n",
    "        for hash,date, files_action, merge_value in zip(c['hash'],c[date],c['files_action'],c['merge']):\n",
    "            current_count = 1\n",
    "            date= date.replace(tzinfo = None)  \n",
    "            if since and date < dateutil.parser.parse(since):\n",
    "                current_count = 0\n",
    "            if until and date > dateutil.parser.parse(until):\n",
    "                current_count = 0\n",
    "            if not empty and files_action == 0 :\n",
    "                current_count = 0\n",
    "            if not merge and merge_value:\n",
    "                current_count = 0\n",
    "            if hash not in unique:\n",
    "                count+=current_count\n",
    "                unique.add(hash)\n",
    "        return count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method `total_count()` implements `Total Count` aggregation for `Code_Changes`.\n",
    "\n",
    "Method `count()` implements `Count` aggregation for `Code_Changes`.\n",
    "It accepts parameters specified for the general metric:\n",
    "    \n",
    "* Period of time: `since` and `until`\n",
    "* Specific case if Git: `merge` and `empty`\n",
    "* `date`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples of use of the implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code changes total count: 1135\n",
      "Code changes count all period: 1135\n",
      "Code changes count from 2017-01-01 to 2019-07-01: 262\n",
      "Code changes count from 2017-01-01 to 2019-07-01 (no merge commits): 234\n",
      "Code changes count from 2017-01-01 to 2019-07-01 (no empty commits): 237\n"
     ]
    }
   ],
   "source": [
    "# giving the data source as an argument, calling the class file \n",
    "changes = Code_Changes('../data/elasticsearch-py.json')\n",
    "\n",
    "\n",
    "print(\"Code changes total count:\", changes.total_count())\n",
    "print(\"Code changes count all period:\", changes.count())\n",
    "print(\"Code changes count from 2017-01-01 to 2019-07-01:\",changes.count(since=\"2017-01-01\", until=\"2019-07-01\"))\n",
    "print(\"Code changes count from 2017-01-01 to 2019-07-01 (no merge commits):\",changes.count(since=\"2017-01-01\", until=\"2019-07-01\", merge=False))\n",
    "print(\"Code changes count from 2017-01-01 to 2019-07-01 (no empty commits):\",changes.count(since=\"2017-01-01\", until=\"2019-07-01\", empty=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Examples showing peculiarities of git commits\n",
    "\n",
    "Let's prepare a dictionary, `commits`, with all commits retrieved,\n",
    "by reading the `elasticsearch-py.json` file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "commits = changes.content\n",
    "count = changes.commit_count"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Naive count of commits\n",
    "\n",
    "Let's compute number of commits the easiest way: just count all commits:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Code Commits (naive): 1135\n"
     ]
    }
   ],
   "source": [
    "print(\"Code Commits (naive):\", count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Issues and PRs \n",
    "\n",
    "The `category` in the json file determines whether it is an issue or pull_request."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Summary:\n",
      " Total Commits 1135 \n",
      " Total Issues 906 \n",
      " Total Pull Requests: 290\n"
     ]
    }
   ],
   "source": [
    "print(\"Summary:\\n\", \"Total Commits\", changes.commit_count, \"\\n\", \"Total Issues\", changes.issue_count, \"\\n\", \"Total Pull Requests:\", changes.pr_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Total Summary  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----Overall Summary-----\n",
      "\n",
      "Code changes total count: 1135\n",
      "Code changes count all period: 1135\n",
      "Code changes count from 2017-01-01 to 2019-07-01: 262\n",
      "Code changes count from 2017-01-01 to 2019-07-01 (no merge commits): 234\n",
      "Code changes count from 2017-01-01 to 2019-07-01 (no empty commits): 237\n",
      "Code Commits (naive): 1135\n",
      "Summary:\n",
      " Total Commits 1135 \n",
      " Total Issues 906 \n",
      " Total Pull Requests: 290\n"
     ]
    }
   ],
   "source": [
    "print('-----Overall Summary-----'+'\\n')\n",
    "\n",
    "print(\"Code changes total count:\", changes.total_count())\n",
    "print(\"Code changes count all period:\", changes.count())\n",
    "print(\"Code changes count from 2017-01-01 to 2019-07-01:\",changes.count(since=\"2017-01-01\", until=\"2019-07-01\"))\n",
    "print(\"Code changes count from 2017-01-01 to 2019-07-01 (no merge commits):\",changes.count(since=\"2017-01-01\", until=\"2019-07-01\", merge=False))\n",
    "print(\"Code changes count from 2017-01-01 to 2019-07-01 (no empty commits):\",changes.count(since=\"2017-01-01\", until=\"2019-07-01\", empty=False))\n",
    "print(\"Code Commits (naive):\", count)\n",
    "print(\"Summary:\\n\", \"Total Commits\", changes.commit_count, \"\\n\", \"Total Issues\", changes.issue_count, \"\\n\", \"Total Pull Requests:\", changes.pr_count)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
